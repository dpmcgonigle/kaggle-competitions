{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h1 style = \"font-size:60px; font-family:Monaco ; font-weight : normal; background-color: #000055 ; color : #9999ff; text-align: center; border-radius: 50px 50px;\">SETI - Breakthrough Listen<br>EfficientNet B3</h1>\n",
    "<br>\n",
    "\n",
    "## Description of problem\n",
    "The vast distances between stars/galaxies and the dramatic effects of the inverse square law make finding electromagnetic signals of intelligent civilizations a challenging task.  Breakthroughs in machine learning using computer vision and time series analysis are tools that may bring us closer to achieving this goal.  The purpose of this notebook, and the greater experiment that this notebook belongs to is to attempt to push the state of the art ever closer to realizing this goal.\n",
    "\n",
    "## Seti Breakthrough-Listen Dataset\n",
    "The purpose of this notebook is to use a pre-trained efficient-net model to classify cadence samples as negative or positive(anomolous signal).  The data consists of \"cadence snippets taken from the Green Bank Telescope\", which is a digital spectrometer that generates spectrograms using the Fourier Transform technique.  The data represent signal intensity as a function of frequency and time.  \n",
    "\n",
    "The \"Cadence\" is described in the \"Data Information\" section of the competition:  \n",
    "5 minutes on star “A”, then 5 minutes on star “B”, then back to star “A” for 5 minutes, then “C”, then back to “A”, then finishing with 5 minutes on star “D”. One set of six observations (ABACAD) is referred to as a “cadence”.  \n",
    "\n",
    "The shape of the data is (6, 273, 256), where 273 represents the time (5 minutes) dimension, and 256 represents the frequency dimension.  \n",
    "\n",
    "\n",
    "## This notebook originally created by: \n",
    "https://www.kaggle.com/anirudhg15/seti-et-baseline-efficientnetb3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# DL Modules\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import efficientnet.tfkeras as efn\n",
    "\n",
    "# ML / Data Prep\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-008ed82026e4>:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if GPU available\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir: str = \"/data/data/datasets/seti/\"\n",
    "train_labels: pd.DataFrame = pd.read_csv(os.path.join(datadir, \"train_labels.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_to_path(sample_id: str) -> str:\n",
    "    \"\"\" Return full path to numpy file from sample id \"\"\"\n",
    "    return os.path.join(datadir, \"train\", sample_id[0], f\"{sample_id}.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LENGTHS ; X_train : 38400, X_val (9600,), X_test (12000,)\n",
      "Number of positive samples ; y_train : 3840, y_val: 960, y_test: 1200\n",
      "Ratio of positive samples ; y_train : 0.100, y_val: 0.100, y_test: 0.100\n"
     ]
    }
   ],
   "source": [
    "X = train_labels['id'].values\n",
    "y = train_labels['target'].values\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = model_selection.train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(\n",
    "    X_trainval, \n",
    "    y_trainval, \n",
    "    test_size=.2, \n",
    "    random_state=42, \n",
    "    stratify=y_trainval\n",
    ")\n",
    "\n",
    "print(f\"LENGTHS ; X_train : {len(X_train)}, X_val {X_val.shape}, X_test {X_test.shape}\")\n",
    "print(f\"Number of positive samples ; y_train : {np.sum(y_train==1)}, y_val: {np.sum(y_val==1)}, y_test: {np.sum(y_test==1)}\")\n",
    "print(f\"Ratio of positive samples ; y_train : {np.sum(y_train==1)/len(y_train):.3f}, y_val: {np.sum(y_val==1)/len(y_val):.3f}, y_test: {np.sum(y_test==1)/len(y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0add6ccf9b2e9ce', '1e4cb3f498e29ca', 'b6606b085a618f1'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, x_set, y_set=None, batch_size=32):\n",
    "        self.x , self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.is_train = False if y_set is None else True\n",
    "        \n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_ids = self.x[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        if self.y is not None:\n",
    "            batch_y = self.y[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        \n",
    "        list_x = [np.load(id_to_path(x))[::2] for x in batch_ids]\n",
    "        batch_x = np.moveaxis(list_x,1,-1)\n",
    "        batch_x = batch_x.astype(\"float\") / 255\n",
    "        \n",
    "        if self.is_train:\n",
    "            return batch_x, batch_y\n",
    "        else:\n",
    "            return batch_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (273, 256, 3)\n",
    "batch_size = 16\n",
    "n_epoch = 2\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnet-b3 (Model)      (None, 9, 8, 1536)        10783528  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 1537      \n",
      "=================================================================\n",
      "Total params: 10,785,065\n",
      "Trainable params: 10,697,769\n",
      "Non-trainable params: 87,296\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "        efn.EfficientNetB3(input_shape=input_size,weights='imagenet',include_top=False),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss='binary_crossentropy', metrics=[keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2400/2400 [==============================] - 565s 235ms/step - loss: 0.3245 - auc: 0.5703 - val_loss: 0.2897 - val_auc: 0.6604\n",
      "Epoch 2/2\n",
      "2400/2400 [==============================] - 569s 237ms/step - loss: 0.2727 - auc: 0.7190 - val_loss: 0.2715 - val_auc: 0.7028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa19c1db340>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = DataGenerator(X_train, y_train, batch_size=batch_size)\n",
    "val = DataGenerator(X_val, y_val, batch_size=batch_size)\n",
    "test = DataGenerator(X_test, batch_size=batch_size)\n",
    "\n",
    "model.fit(train, validation_data=val, epochs=n_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dan/anaconda3/envs/kaggle3811/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: models/effnet_cadences_E2/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(os.path.join(\"models\", \"effnet_cadences_E2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = model.predict(test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(preds_test[:4]).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9190833333333334"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, np.round(preds_test).astype(np.int32))\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2400/2400 [==============================] - 533s 222ms/step - loss: 0.2391 - auc: 0.7988 - val_loss: 0.2788 - val_auc: 0.7017\n",
      "Epoch 2/2\n",
      "2400/2400 [==============================] - 530s 221ms/step - loss: 0.1944 - auc: 0.8818 - val_loss: 0.3100 - val_auc: 0.6972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa04c06ab80>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, validation_data=val, epochs=n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9205833333333333"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_test = model.predict(test).flatten()\n",
    "acc = accuracy_score(y_test, np.round(preds_test).astype(np.int32))\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/effnet_cadences_E4/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(os.path.join(\"models\", \"effnet_cadences_E4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 911/2400 [==========>...................] - ETA: 5:14 - loss: 0.1307 - auc: 0.9554"
     ]
    }
   ],
   "source": [
    "for epoch in range(6, 21, 2):\n",
    "    model.fit(train, validation_data=val, epochs=n_epoch)\n",
    "    preds_test = model.predict(test).flatten()\n",
    "    acc = accuracy_score(y_test, np.round(preds_test).astype(np.int32))\n",
    "    print(\"TEST ACCURACY AFTER EPOCH {epoch} : {acc:.6f}\")\n",
    "    model.save(os.path.join(\"models\", f\"effnet_cadences_E{epoch}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle3811",
   "language": "python",
   "name": "kaggle3811"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
